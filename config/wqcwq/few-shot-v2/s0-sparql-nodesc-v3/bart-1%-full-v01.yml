# export PYTHONPATH=`pwd` && echo $PYTHONPATH
# python main/run_pmt_bart.py -c config/wqcwq/few-shot-v2/s0-sparql-nodesc-v3/bart-1%-full-v01.yml

# helper
only_test_mode: false
test_mode: true
debug: false
eval_all: true
grid_search: false

# ver + path
dataset: "wqcwq"
ver: "1%-v03"
serialization_dir: save/wqcwq/s2s-bart-fewshot/sparql-nomid
predictions_output_file: predictions.json
vocabulary: vocabulary
load_weights_file: weights.th
save_weights_file: weights.th
metrics_output_file: evaluate_metric.json
comments: "my参数"
model_name: "pretrained_models/facebook/bart-base"

update_layers: "all"

# path
datasets: "datasets/wqcwq-all-infos-v1.0/all-cvt-pred.jsonl"
ids_map: "datasets/wqcwq-all-infos-v1.0/ids_map_v2.0.json"

load_model: false
# load_model:"save/s2s-bart-fewshot-allBeams/sparql-nomid/1%-full-v01/weights.th"

# optimizer
weight_decay: 1e-5
warmup_proportion: 0.1
adam_epsilon: 1e-8
max_grad_norm: 1.0
alpha: 1e-4
learning_rate: 3e-5
num_gradient_accumulation_steps: 1

# beam
beam_size: 10
max_decoding_steps: 128
beam_length_penalty: 1.2

# data
decoder_prompt: "my question is, "
decoder_instructions: false
beam_sample: null
setting: "sparql-nomid"
max_length: 256

# special
max_instances_percent_train: 0.01
max_instances_percent_dev: 1

# train
num_epochs: 99
max_instances_train: null # 29919it 1%:299  5%:1495  10%:2991
train_batch_size: 32
factor_scheduler: 0.9
patience_scheduler: 2
patience_trainer: 5
cuda_index: 0
grad_clipping: 1.0

# dev
max_instances_dev: null # 2528it
dev_batch_size: 32
dev_batches_per_epoch: 10

# test
max_instances_test: null # 2532it
test_batch_size: 32

# log
log_name: "log.json"